install.packages("logistif")
install.packages("logistf")
require(logistf)
library(logistf)
?logistf
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.4", .libPaths()) )
install.packages("logistf")
library(logistf)
q()
.libPaths()
.libPaths(c(C:/users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library))
.libPaths(c(C:users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library))
.libPaths(c(C:users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library)
.libPaths(c(C:Users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library)
.libPaths(c(C:/Users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library)
.libPaths(c(C:/Users/ankit singh/Documents/R/win-library/3.4,C:/Program Files/R/R-3.4.3/library)
.libPaths(c("C:/Users/ankit singh/Documents/R/win-library/3.4","C:/Program Files/R/R-3.4.3/library)")
)
.libPatjhs()
.libPaths()
install.packages("neuralnet")
library(neuralnet)
?neuralnet
?infert
nn=neuralnet(case~age+parity+induced+spontaneous,data=infert,hidden=2,err.fct="ce",linear.output=FALSE)
nn
plot(nn)
n$weights
nn$weights
nn$esult.matrix
nn$esult.matrix[[1]]
nn$result.matrix[[1]]
nn$result.matrix
nn$net.result
nn1=ifelse(nn$net.result>0.5,1,0)
nn1=ifelse(nn$net.result>0.5,1.0,0.0)
nn$covariate
nn$net.result[[1]]
nn1=ifelse(nn$net.result[[1]]>0.5,1.0,0.0)
misclass=mean(infert$case,nn1)
misclass=mean(infert$case!=nn1)
misclass
nn=neuralnet(case~age+parity+induced+spontaneous,data=infert,hidden=2,learningrate=0.01,algorith="backdrop",err.fct="ce",linear.output=FALSE)
nn=neuralnet(case~age+parity+induced+spontaneous,data=infert,hidden=2,learningrate=0.01,algorithm="backdrop",err.fct="ce",linear.output=FALSE)
nn=neuralnet(case~age+parity+induced+spontaneous,data=infert,hidden=2,learningrate=0.01,algorithm="backprop",err.fct="ce",linear.output=FALSE)
nn
nn.result.matrix
nn$result.matrix
nn$net.result
nn$net.result[[1]]
nn$net.result
nn$net.result
p<-cbind(nn$net.result,nn$net.result[[1]])
p
plot(nn)
covariate=matrix(c(22,1,0,0,
22,1,1,0,
22,1,0,1,
22,1,1,1),
byrow=TRUE,ncol=4)
covariate
nn.pred=compute(nn,covariate)
nn.net$result
nn$net.result
nn.ped$net.result
nn.pred$net.result
nn=neuralnet(case~age+parity+induced+spontaneous,data=infert,hidden=2,err.fct="ce",linear.output=FALSE)
nn.pred=compute(nn,covariate)
nn.pred$net.result
ci=confidence.interval(nn,alpha=0.5)
ci
par(mfrow=c(2,2))
gwplot(nn,select.covariate="age",min=2.5,max=5)
?gwplot
par(mfrow=c(2,2))
gwplot(nn,select.covariate="age",min=2.5,max=5)
gwplot(nn,select.covariate="parity",min=2.5,max=5)
gwplot(nn,select.covariate="induced",min=2.5,max=5)
gwplot(nn,select.covariate="spontaneous",min=2.5,max=5)
par(mfrow=c(2,2))
gwplot(nn,selected.covariate="age",min=2.5,max=5)
gwplot(nn,selected.covariate="parity",min=2.5,max=5)
gwplot(nn,selected.covariate="induced",min=2.5,max=5)
gwplot(nn,selected.covariate="spontaneous",min=2.5,max=5)
par(mfrow=c(2,2))
gwplot(nn,selected.covariate="age",min=-2.5,max=5)
gwplot(nn,selected.covariate="parity",min=2.5,max=5)
gwplot(nn,selected.covariate="induced",min=2.5,max=5)
gwplot(nn,selected.covariate="spontaneous",min=2.5,max=5)
q()
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.3", .libPaths()) )
library(DMvR)
install.packages("DMvR")
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.4", .libPaths()) )
install.packages("DMvR")
utils:::menuInstallLocal()
utils:::menuInstallPkgs()
library(DMwR)
data(algae)
head(algae)
complete.cases(algae)
complete.cases(algae,0.2)
nrow[!complete.cases(algae)]
nrow(algae[!complete.cases(algae),])
manyNAs(algae,0.2)
algae[-manyNAs(algae,0.2),]
nrow(algae)
algae=algae[-manyNAs(algae,0.2),]
nrow(algae)
fix(algae)
>\?cor
?cor
symnum(cor(algae[,4:18],use="everything"))
symnum(cor(algae[,4:18],use="complete.obs"))
data(algae)
nrow(algae)
algae[-manyNAs(algae,0.2),]
algae=algae[-manyNAs(algae,0.2),]
lm(PO4~oPO4,data=algae)
?knn.Imputation
??knn.Imputation
require(imputation)
??knnImputation
algae<-knnImputation(algae,k=10,meth="median")
fix(algae)
base
library(plyr)
library(dplyr)
library(lubridate)
base
q()
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.4", .libPaths()) )
irisdata=read.csv("C:\Users\ankit singh\Desktop\irisdata.csv")
irisdata=read.csv("C:/Users/ankit singh/Desktop/irisdata.csv")
irisdata
dim(irisdata)
pairs(irisdata)
names(irisdata)
str(irisdata)
summary(irisdata)
iris<-irisdata
colnames(iris)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
head(iris)
set.sedd(2)
set.seed(2)
traindata=sample(1:149,0.8*149)
testdata=-traindata
test=iris[test,]
test=iris[testdata,]
train=iris[traindata,]
head(testdata)
head(test)
head(train)
par(mfrow=c(1,4))
  for(i in 1:4) {
  boxplot(trainset[,i], main=names(trainset)[i])
}
par=(mfrow=c(1,4))
for(i in 1:4){
  boxplot(train[,i], main=names(train)[i])
}
setosa=train(iris$Species=Iris-setosa)
setosa=train[iris$Species=Iris-setosa
train
train[,Species=Iris-setosa]
train[,Species]
train[,species]
train[,Species="Iris-setosa"]
?tree
install.packages("tree")
tree.model=tree(Species~.,data=train)
library(tree)
tree.model=tree(Species~.,data=train)
plot(tree.model)
text(tree.model,pretty=0)
pred.model=predict(tree.model,newdata=test,type="class")
table(pred.model,iris$Species)
table(pred.model,train$Species)
table(pred.model,test$Species)
mean(pred.model!=test$Species)
set.seed(2)
cv_tree=cv.tree(tree.model,FUN=misclass)
?cv.tree
cv_tree=cv.tree(tree.model,FUN=prune.misclass)
plot(cv_tree)
plot(cv_tree$size,cv_tree$dev,type="b")
pruned_model=prune.misclass(tree.model,best=3)
pred.prune.model=predict(pruned.model,newdata=test,type="class")
pred.prune.model=predict(pruned_model,newdata=test,type="class")
table(pred.prune.model,test$Species)
mean(pred.prune.model!=test$Species)
inatll.packages("randomForest")
install.packages("randomForest")
install.packages("gbm")
require(gbm)
require(randomForest)
?randomFores
?randomForest
MSE.rf=rep(0,4)
for(d in 1:4){
rf.model=randomForest(Species~.,data=train,mtry=d,importance=T)
rf.pred=predict(rf.model,newdata=test)
mean(rf.pred!=test$Species)
}
mtry=c(1:4)
plot(mtry,MSE.rf=rep(0,4)
for(d in 1:4){
rf.model=randomForest(Species~.,data=train,mtry=d,importance=T)
rf.pred=predict(rf.model,newdata=test)
MSE.rf[d]=mean(rf.pred!=test$Species)
}
MSE.rf=rep(0,4)
for(d in 1:4){
rf.model=randomForest(Species~.,data=train,mtry=d,importance=T)
rf.pred=predict(rf.model,newdata=test)
MSE.rf[d]=mean(rf.pred!=test$Species)
}
plot(mtry,MSE.rf)
MSE.rf
boost.model=gbm(Species~.,data=train,distribution="bernulli",ntree=5000,interaction.depth2=2,shrinkage=0.01)
boost.model=gbm(Species~.,data=train,distribution="bernulli",ntree=5000,interaction.depth=2,shrinkage=0.01)
boost.model=gbm(Species~.,data=train,distribution="bernulli",n.tree=5000,interaction.depth=2,shrinkage=0.01)
?gbm
boost.model=gbm(Species~.,data=train,distribution="bernoulli",n.tree=5000,interaction.depth=2,shrinkage=0.01)
boost.model=gbm(Species~.,data=train,distribution="multinomial",n.tree=5000,interaction.depth=2,shrinkage=0.01)
summary(boost.model)
boost.pred=predict(boost.model,newdata=test)
boost.pred=predict(boost.model,newdata=test,n.tree=5000)
mean(test$Species!=boost.pred)
boost.pred
boost.pred.val=boost.pred[,max(c(1:3))]
lda.fit=lda(Species~.,data=train)
require(MASS)
lda.fit=lda(Species~.,data=train)
lda.pred=predict(lda.fit,newdata=test)
mean(lda.pred!=iris$Species)
lda.fit=lda(Species~.,data=train,,amily="binomial"))
lda.fit=lda(Species~.,data=train,,amily="binomial")
lda.fit=lda(Species~.,data=train,,family="binomial")
lda.fit=lda(Species~.,data=train,,family=binomial)
?lda
iris$Species=as.factor(iris$Species)
test=iris[,testdata]
train=iris[,traindata]
train=iris[,trainingdata]
ls
ls()
train=iris[traindata,]
test=iris[testdata,]
lda.fit=lda(Species~.,data=train,family=binomial)
lda.pred=predict(lda.fit,newdata=test)
mean(lda.pred!test$Species)
mean(lda.pred!=test$Species)
test$Species
lda.pred
head(test)
head(train)
lda.pred=predict(lda.fit,newdata=test,type=binomial)
lda.pred=predict(lda.fit,newdata=test)
mean(lda.pred!=test$Species)
lda.pred
lda.fit=lda(Species~.,data=train,family=binomial)
lda.pred=predict(lda.fit,newdata=test,type=response)
mean(lda.pred!=test$Species)
lda.pred
lda.pred
mean(lda.pred$class!=test$Species)
boost.model
boost.pred
table(lda.pred$class,test$Species)
table(rf.pred,test$Species)
install.packages("kmeans")
install.packages("kmean")
set.seed(2)
kmeans.model=kmeans(train[,1:4],3,nstart=20)
kmeans
kmeans.model
kmeans.predict=predict(kmeans.model,newdata=test)
names(kmeans.model)
kmeans.model$cluster
kmeans.model$cluster==test$Species
table(kmeans.model$cluster,test$Species)
table(kmeans.model$cluster,train$Species)
boost.pred
table(boost.pred,test$Species)
names(boost.pred)'
names(boost.pred)'
names(boost.pred)
pred=as.matrix(boost.pred[,,1])
table(pred,test$Species)
pred
pred$new_col<-colname(max(pred$Iris-setosa,pred$Iris-versicolor,pred$Iris-virginica))
pred$new_col<-colnames(max(pred$Iris-setosa,pred$Iris-versicolor,pred$Iris-virginica))
which.max(pred=as.matrix(probs.var.multinom[,,1])
which.max(max(pred$Iris-setosa,pred$Iris-versicolor,pred$Iris-virginica)))
which.max(max(pred$Iris-setosa,pred$Iris-versicolor,pred$Iris-virginica))
p.predBST <- apply(pred, 1, which.max)
p.predBST
?apply
table(p.predBST,test$Species)
mean(p.predBST!=test$Species)
lda.pred
mean(lda.pred.class$test$Species)
mean(lda.pred$class$test$Species)
mean(lda.pred$class!=test$Species)
q()
data(iris)
barplot(iris$Petal.Length)
iris$Sepal.Length
iris
barplot(iris$Sepal.Width,col=(iris$Sepal.Width))
barplot(iris$Sepal.Width,col=(iris$Species))
table(iris$Sepal.Width,iris$Species)
barplot(table(iris$Sepal.Width,iris$Species),col=brewer.pal(3,"Set1"))
barplot(table(iris$Sepal.Width,iris$Species))
barplot(table(iris$Sepal.Width,iris$Species))
barplot(table(iris$Species,iris$Sepal.Width))
iris$Sepal.Length~iris$Species
boxplot(iris$Sepal.Length~iris$Species)
table(iris$Sepal.Length,iris$Species)
table(iris$Sepal.Length,iris$Species,iris$Species)
table(iris$Species,iris$Sepal.Length)
boxplot(table(iris$Species,iris$Sepal.Length))
table(iris$Sepal.Length,iris$Species,iris$Species)
boxplot(table(iris$Species,iris$Sepal.Length))
boxplot(table(iris$Species,iris$Sepal.Length))
boxplot(iris$Sepal.Length~iris$Species)
library(hexbin)
install.packages("hexbin")
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.4", .libPaths()) )
install.packages("hexbin")
data(diamonds)
a=hexbin(iris$Sepal.Width,iris$Species,xbins=10)
library(hexbin)
a=hexbin(iris$Sepal.Width,iris$Species,xbins=10)
plot(a)
mtcars
data(mtcars)
data
b<as.matrix(mtcars)
b<-as.matrix(mtcars)
b
heatmap(mtcars)
heatmap(b)
image(as.matrix(b[2:7]))
q()
.libPaths( c( "C:\Users\ankit singh\Documents\R\win-library\3.4" , .libPaths() ) )
.libPaths( c( "C:/Users/ankit singh/Documents/R/win-library/3.4" , .libPaths() ) )
getwd()
setwd("F:\r_git_upload\multivariate")
setwd("F:/r_git_upload/multivariate")
getwd()
sale1
.libPaths( c( "C:\Users\ankit singh\Documents\R\win-library\3.4" , .libPaths() ) )
 sales = read.csv("F://r_git_upload//multivariate//data//Data.csv",header = T)
View(sales)
str(sales)
drop=c("Date")
sale1=sales[ ,!(names(sales) %in% drop)]
str(sale1)
sale1$MarkDown2 = ifelse(is.na(sale1$MarkDown2), mean(sale1$MarkDown2, na.rm=TRUE), sale1$MarkDown2)
cor(sale1)
install.packages("corrplot")
library("corrplot")
corrplot(cor(sale1))
#Performing regression on the data
attach(sale1)
fit0 <- lm(Weekly_Sales ~ Temperature + Fuel_Price + MarkDown1+ MarkDown2 + MarkDown3 + MarkDown4 + MarkDown5 + CPI + Unemployment + as.factor(IsHoliday), data=sale1)
summary(fit0)
#VIF calculation
library("car")
vif(fit0)
#reaching a proper fit by removing markdown3 because of high pr value 
fit <- lm(Weekly_Sales ~ Temperature + Fuel_Price + MarkDown1 + MarkDown2 + MarkDown4 + MarkDown5 + CPI + Unemployment + as.factor(IsHoliday), data=sale1)
summary(fit)
vif(fit)
#reaching a proper fit by removing markdown1, Fuel_Price and IsHoliday because of high pr value as well
fit <- lm(Weekly_Sales ~ Temperature + MarkDown2 + MarkDown4 + MarkDown5 + CPI + Unemployment , data=sale1)
summary(fit)
vif(fit)
#removing Temperature of high pr value
fit <- lm(Weekly_Sales ~ MarkDown2 + MarkDown4 + MarkDown5 + CPI + Unemployment , data=sale1)
summary(fit)
vif(fit)
# we can see atleast right now the adjusted R-square value is positive but none of the variables
# are significant. SO we are trying for a automatic regression, which is stepwise regression
# function.
library(MASS)
step_fit = stepAIC(fit0, direction = "both")
summary(step_fit)
# So we can see that there are nothing significant variable to predict our dependent variable.
sale1
install.packages("rpart.plot")
# Regression Tree Example
library(rpart)
library(rattle)
library(rpart.plot)
fit <- rpart(Weekly_Sales~., method="anova", data=sale1)
printcp(fit) # display the results  cp is complexity parameter
summary(fit) # detailed summary of splits
par(mfrow=c(1,2)) # two plots on one page 
rsq.rpart(fit) # visualize cross-validation results   
fit
# plot tree 
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
plot(fit)
par(mfrow=c(1,2)) # two plots on one page 
rsq.rpart(fit) # visualize cross-validation results   
fit
rsq.rpart(fit)
par(mfrow=c(1,2)) # two plots on one page 
rsq.rpart(fit) # visualize cross-validation results
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
library(rpart.plot)
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
?fancyRpartPlot
??fancyRpartPlot
??fancyrpartplot
install.packages("rattle")
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
library("rattle")
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
 plot(fit, uniform=TRUE,margin=0.2)
text(fit, use.n=TRUE, all=TRUE, cex=.8)
 plot(fit, uniform=TRUE,margin=0.2)
text(fit, use.n=TRUE, all=TRUE, cex=.8)
sale1
printcp(fit) # display the results  cp is complexity parameter
summary(fit)
fancyRpartPlot(fit,uniform=TRUE,main="Regression Tree for Weekly_sales")
library(fpc)
library(cluster)
install.packages("fpc");
library("fpc")
library(fpc)
utils:::menuInstallPkgs()
install.packages("mvtnorm");
install.packages("fpc");
library(mvtnorm)
library("mvtnorm")
drop=c("IsHoliday")
sale2=sale1[ ,!(names(sale1) %in% drop)]
sale2
sale_norm = scale(sale2)
sale_norm 
sum(is.na(sale2)==TRUE)
set.seed(500)
set.seed(500)
#to find out how many clusters
wss <- (nrow(sale_norm)-1)*sum(apply(sale_norm,2,var))
for (i in 1:5) wss[i] <- sum(kmeans(sale_norm, centers=i)$withinss)
plot(1:5, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
#forming clusters
results= kmeans(sale_norm,5)
results
clusplot(sale_norm[,1:10], results$cluster, color=TRUE, shade=TRUE,labels=2, lines=0)
results$cluster
a=data.frame(sale2,results$cluster)
View(a)
data1 = split(a,a$results.cluster)
#creating data frames from the clusters
firstcluster = data1$`1`
secondcluster=data1$`2`
thirdcluster=data1$`3`
fourthcluster=data1$`4`
fivecluster=data1$`5`
library(psych)
desc1 = data.frame(round(describe(firstcluster),2))
desc2 = data.frame(round(describe(secondcluster),2))
desc3 = data.frame(round(describe(thirdcluster),2))
desc4 = data.frame(round(describe(fourthcluster),2))
desc5 = data.frame(round(describe(fivecluster),2))
#Print the above created table in pdf format
library(gridExtra)
pdf("Descriptive_1stcluster.pdf",height = 8,width = 10)
grid.table(desc1[-11,-c(1,6,7,11)])
dev.off()
pdf("Descriptive_2ndcluster.pdf",height = 8,width = 10)
grid.table(desc2[-11,-c(1,6,7,11)])
dev.off()
pdf("Descriptive_3rdcluster.pdf",height = 8,width = 10)
grid.table(desc3[-11,-c(1,6,7,11)])
dev.off()
pdf("Descriptive_4thcluster.pdf",height = 8,width = 10)
grid.table(desc4[-11,-c(1,6,7,11)])
dev.off()
pdf("Descriptive_5thcluster.pdf",height = 8,width = 10)
grid.table(desc5[-11,-c(1,6,7,11)])
dev.off()
library(randomForest)
library(e1071)
library(MASS)
fit1 <- lm(Weekly_Sales ~ Temperature + Fuel_Price + MarkDown1+ MarkDown2 + MarkDown3 + MarkDown4 + MarkDown5 + CPI + Unemployment, data=firstcluster)
step_firstcluster <- stepAIC(fit1, direction="both")
summary(step_firstcluster)
ran_fit1 = randomForest(Weekly_Sales ~ Temperature + Fuel_Price + MarkDown1+ MarkDown2 + MarkDown3 + 
                          MarkDown4 + MarkDown5 + CPI + Unemployment, data=firstcluster, ntree=500, importance=T)
plot(ran_fit1)
varImpPlot(ran_fit1,
           sort = T,
           main="Variable Importance",
           n.var=5)
svm1 = svm(Weekly_Sales ~ CPI + Unemployment + MarkDown4 + MarkDown1, data = firstcluster)
summary(svm1)
predicted1 <- predict(svm1, firstcluster)
#variance explained with SVM
100-mean(abs((firstcluster$Weekly_Sales-predicted1)/firstcluster$Weekly_Sales)*100)
varImpPlot(ran_fit1,
           sort = T,
           main="Variable Importance",
           n.var=5)
q()
